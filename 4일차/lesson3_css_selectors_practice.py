"""
ì›¹ ìŠ¤í¬ë ˆì´í•‘ ì…ë¬¸ - 3êµì‹œ: CSS ì„ íƒìë¥¼ í™œìš©í•œ ì •ë°€ ë°ì´í„° ìˆ˜ì§‘ ì‹¤ìŠµ

ëŒ€ìƒ: íŒŒì´ì¬ì„ ì²˜ìŒ ë°°ìš°ëŠ” ì§ì¥ì¸
í•™ìŠµ ì‹œê°„: 50ë¶„
"""

import requests
from bs4 import BeautifulSoup
import csv
from datetime import datetime


# ============================================================================
# ì„¹ì…˜ 1: CSS ì„ íƒì ê¸°ì´ˆ
# ============================================================================

def section1_css_basics():
    """ì„¹ì…˜ 1: CSS ì„ íƒì ê¸°ì´ˆ"""
    print("\n" + "="*70)
    print("ì„¹ì…˜ 1: CSS ì„ íƒì ê¸°ì´ˆ")
    print("="*70)
    
    print("\n[ì´ë¡ ]")
    print("CSS ì„ íƒìëŠ” HTML ìš”ì†Œë¥¼ ì°¾ê¸° ìœ„í•œ íŒ¨í„´ì…ë‹ˆë‹¤.")
    print("ì›¹ ë””ìì´ë„ˆê°€ ìŠ¤íƒ€ì¼ì„ ì ìš©í•˜ëŠ” ë°©ì‹ê³¼ ë™ì¼í•©ë‹ˆë‹¤.")
    
    html = """
    <div class="container">
        <h1 id="main-title">ë©”ì¸ ì œëª©</h1>
        <div class="article">
            <h2>ì²« ë²ˆì§¸ ê¸°ì‚¬</h2>
            <p>ë‚´ìš© 1</p>
        </div>
        <div class="article">
            <h2>ë‘ ë²ˆì§¸ ê¸°ì‚¬</h2>
            <p>ë‚´ìš© 2</p>
        </div>
        <div class="notice">
            <h2>ê³µì§€ì‚¬í•­</h2>
        </div>
    </div>
    """
    
    soup = BeautifulSoup(html, 'html.parser')
    
    print("\n[ì˜ˆì œ 1-1] íƒœê·¸ ì„ íƒì")
    print("-" * 50)
    
    # ëª¨ë“  h2 íƒœê·¸
    h2_tags = soup.select('h2')
    print(f"ëª¨ë“  h2 íƒœê·¸ ({len(h2_tags)}ê°œ):")
    for i, h2 in enumerate(h2_tags, 1):
        print(f"{i}. {h2.text}")
    
    print("\n[ì˜ˆì œ 1-2] í´ë˜ìŠ¤ ì„ íƒì (.)")
    print("-" * 50)
    
    # .article í´ë˜ìŠ¤
    articles = soup.select('.article')
    print(f"article í´ë˜ìŠ¤ ({len(articles)}ê°œ):")
    for i, article in enumerate(articles, 1):
        h2 = article.select_one('h2')
        print(f"{i}. {h2.text}")
    
    # div.article (divì´ë©´ì„œ article í´ë˜ìŠ¤)
    div_articles = soup.select('div.article')
    print(f"\ndiv.article ({len(div_articles)}ê°œ):")
    for article in div_articles:
        print(f"- {article.select_one('h2').text}")
    
    print("\n[ì˜ˆì œ 1-3] ID ì„ íƒì (#)")
    print("-" * 50)
    
    # #main-title ID
    title = soup.select_one('#main-title')
    print(f"ID 'main-title': {title.text}")
    
    print("\n[ì„¤ëª…]")
    print("1. 'tag' - íƒœê·¸ ì´ë¦„ìœ¼ë¡œ ì°¾ê¸°")
    print("2. '.class' - í´ë˜ìŠ¤ë¡œ ì°¾ê¸°")
    print("3. '#id' - IDë¡œ ì°¾ê¸°")
    print("4. 'tag.class' - íƒœê·¸ì™€ í´ë˜ìŠ¤ ì¡°í•©")


# ============================================================================
# ì„¹ì…˜ 2: ì†ì„± ì„ íƒìì™€ ì¡°í•©
# ============================================================================

def section2_advanced_selectors():
    """ì„¹ì…˜ 2: ê³ ê¸‰ ì„ íƒì"""
    print("\n" + "="*70)
    print("ì„¹ì…˜ 2: ì†ì„± ì„ íƒìì™€ ì¡°í•©")
    print("="*70)
    
    print("\n[ì´ë¡ ]")
    print("ì†ì„± ì„ íƒìë¡œ ë” ì •ë°€í•˜ê²Œ ìš”ì†Œë¥¼ ì°¾ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
    
    html = """
    <div class="links">
        <a href="/news/1">ë‰´ìŠ¤ 1</a>
        <a href="/news/2">ë‰´ìŠ¤ 2</a>
        <a href="/notice/1">ê³µì§€ 1</a>
        <a href="https://external.com">ì™¸ë¶€ ë§í¬</a>
        <img src="image1.jpg" alt="ì´ë¯¸ì§€1">
        <img src="image2.png" alt="ì´ë¯¸ì§€2">
    </div>
    """
    
    soup = BeautifulSoup(html, 'html.parser')
    
    print("\n[ì˜ˆì œ 2-1] ì†ì„± ì¡´ì¬ í™•ì¸ [attr]")
    print("-" * 50)
    
    # href ì†ì„±ì´ ìˆëŠ” a íƒœê·¸
    links = soup.select('a[href]')
    print(f"href ì†ì„±ì´ ìˆëŠ” ë§í¬: {len(links)}ê°œ")
    
    print("\n[ì˜ˆì œ 2-2] ì†ì„± ê°’ìœ¼ë¡œ í•„í„°ë§")
    print("-" * 50)
    
    # hrefê°€ "/news"ë¡œ ì‹œì‘í•˜ëŠ” ë§í¬
    news_links = soup.select('a[href^="/news"]')
    print(f"ë‰´ìŠ¤ ë§í¬ ({len(news_links)}ê°œ):")
    for link in news_links:
        print(f"- {link.text}: {link['href']}")
    
    # hrefê°€ "http"ë¡œ ì‹œì‘í•˜ëŠ” ë§í¬ (ì™¸ë¶€ ë§í¬)
    external = soup.select('a[href^="http"]')
    print(f"\nì™¸ë¶€ ë§í¬ ({len(external)}ê°œ):")
    for link in external:
        print(f"- {link.text}: {link['href']}")
    
    # srcê°€ ".jpg"ë¡œ ëë‚˜ëŠ” ì´ë¯¸ì§€
    jpg_images = soup.select('img[src$=".jpg"]')
    print(f"\nJPG ì´ë¯¸ì§€ ({len(jpg_images)}ê°œ):")
    for img in jpg_images:
        print(f"- {img['alt']}: {img['src']}")
    
    print("\n[ì˜ˆì œ 2-3] ì†ì„±ì— íŠ¹ì • ê°’ í¬í•¨")
    print("-" * 50)
    
    # hrefì— "news"ê°€ í¬í•¨ëœ ë§í¬
    contains_news = soup.select('a[href*="news"]')
    print(f"'news' í¬í•¨ ë§í¬: {len(contains_news)}ê°œ")
    
    print("\n[ì„¤ëª…]")
    print("1. [attr] - ì†ì„±ì´ ìˆëŠ” ìš”ì†Œ")
    print("2. [attr='value'] - ì†ì„± ê°’ì´ ì •í™•íˆ ì¼ì¹˜")
    print("3. [attr^='value'] - ì†ì„± ê°’ì´ valueë¡œ ì‹œì‘")
    print("4. [attr$='value'] - ì†ì„± ê°’ì´ valueë¡œ ëë‚¨")
    print("5. [attr*='value'] - ì†ì„± ê°’ì— value í¬í•¨")


# ============================================================================
# ì„¹ì…˜ 3: ìì†/ìì‹ ì„ íƒì
# ============================================================================

def section3_descendant_child():
    """ì„¹ì…˜ 3: ìì†ê³¼ ìì‹ ì„ íƒì"""
    print("\n" + "="*70)
    print("ì„¹ì…˜ 3: ìì†/ìì‹ ì„ íƒì")
    print("="*70)
    
    print("\n[ì´ë¡ ]")
    print("ê³µë°±( ) = ìì† (ëª¨ë“  í•˜ìœ„ ìš”ì†Œ)")
    print(">      = ìì‹ (ì§ì ‘ í•˜ìœ„ ìš”ì†Œë§Œ)")
    
    html = """
    <div class="container">
        <p>ì§ì ‘ ìì‹ p</p>
        <div class="content">
            <p>ì†ì p</p>
            <div>
                <p>ì¦ì†ì p</p>
            </div>
        </div>
    </div>
    """
    
    soup = BeautifulSoup(html, 'html.parser')
    
    print("\n[ì˜ˆì œ 3-1] ìì† ì„ íƒì (ê³µë°±)")
    print("-" * 50)
    
    # container ì•„ë˜ì˜ ëª¨ë“  p (ìì†)
    all_p = soup.select('.container p')
    print(f"container ì•„ë˜ ëª¨ë“  p: {len(all_p)}ê°œ")
    for i, p in enumerate(all_p, 1):
        print(f"{i}. {p.text}")
    
    print("\n[ì˜ˆì œ 3-2] ìì‹ ì„ íƒì (>)")
    print("-" * 50)
    
    # containerì˜ ì§ì ‘ ìì‹ pë§Œ
    direct_p = soup.select('.container > p')
    print(f"containerì˜ ì§ì ‘ ìì‹ p: {len(direct_p)}ê°œ")
    for p in direct_p:
        print(f"- {p.text}")
    
    # contentì˜ ì§ì ‘ ìì‹ p
    content_p = soup.select('.content > p')
    print(f"\ncontentì˜ ì§ì ‘ ìì‹ p: {len(content_p)}ê°œ")
    for p in content_p:
        print(f"- {p.text}")
    
    print("\n[ì„¤ëª…]")
    print("1. 'A B' - A ì•„ë˜ì˜ ëª¨ë“  B (ê¹Šì´ ë¬´ê´€)")
    print("2. 'A > B' - Aì˜ ì§ì ‘ ìì‹ Bë§Œ")
    print("3. ì •ë°€í•œ ì„ íƒì´ í•„ìš”í•  ë•Œ > ì‚¬ìš©")


# ============================================================================
# ì„¹ì…˜ 4: ì—¬ëŸ¬ ì„ íƒì ì¡°í•©
# ============================================================================

def section4_multiple_selectors():
    """ì„¹ì…˜ 4: ì—¬ëŸ¬ ì„ íƒì ì¡°í•©"""
    print("\n" + "="*70)
    print("ì„¹ì…˜ 4: ì—¬ëŸ¬ ì„ íƒì ì¡°í•©")
    print("="*70)
    
    print("\n[ì´ë¡ ]")
    print("ì‰¼í‘œ(,)ë¡œ ì—¬ëŸ¬ ì„ íƒìë¥¼ OR ì¡°ê±´ìœ¼ë¡œ ì¡°í•©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
    
    html = """
    <div>
        <h1>ì œëª© 1</h1>
        <h2>ì œëª© 2</h2>
        <h3>ì œëª© 3</h3>
        <p class="important">ì¤‘ìš” ë¬¸ë‹¨</p>
        <p class="normal">ì¼ë°˜ ë¬¸ë‹¨</p>
        <span class="important">ì¤‘ìš” ìŠ¤íŒ¬</span>
    </div>
    """
    
    soup = BeautifulSoup(html, 'html.parser')
    
    print("\n[ì˜ˆì œ 4-1] ì—¬ëŸ¬ íƒœê·¸ ì„ íƒ (,)")
    print("-" * 50)
    
    # h1, h2, h3 ëª¨ë‘ ì„ íƒ
    headings = soup.select('h1, h2, h3')
    print(f"ëª¨ë“  í—¤ë”© íƒœê·¸: {len(headings)}ê°œ")
    for h in headings:
        print(f"- {h.name}: {h.text}")
    
    print("\n[ì˜ˆì œ 4-2] ì—¬ëŸ¬ í´ë˜ìŠ¤ ì„ íƒ")
    print("-" * 50)
    
    # important í´ë˜ìŠ¤ (íƒœê·¸ ë¬´ê´€)
    important = soup.select('.important')
    print(f"important í´ë˜ìŠ¤: {len(important)}ê°œ")
    for elem in important:
        print(f"- {elem.name}: {elem.text}")
    
    print("\n[ì˜ˆì œ 4-3] ë³µì¡í•œ ì¡°í•©")
    print("-" * 50)
    
    # h2 ë˜ëŠ” p.important
    combined = soup.select('h2, p.important')
    print(f"h2 ë˜ëŠ” p.important: {len(combined)}ê°œ")
    for elem in combined:
        print(f"- {elem.name}: {elem.text}")
    
    print("\n[ì„¤ëª…]")
    print("1. 'A, B' - A ë˜ëŠ” B")
    print("2. ì—¬ëŸ¬ ì¡°ê±´ì„ ë™ì‹œì— ë§Œì¡±í•˜ëŠ” ìš”ì†Œë¥¼ ì°¾ì„ ë•Œ ìœ ìš©")
    print("3. ì‰¼í‘œë¡œ êµ¬ë¶„í•˜ì—¬ ë¬´ì œí•œ ì¡°í•© ê°€ëŠ¥")


# ============================================================================
# ì„¹ì…˜ 5: ì‹¤ì „ í”„ë¡œì íŠ¸ - ë‰´ìŠ¤ ê¸°ì‚¬ ìˆ˜ì§‘
# ============================================================================

def section5_news_scraping():
    """ì„¹ì…˜ 5: ì‹¤ì „ - ë‰´ìŠ¤ ê¸°ì‚¬ ìˆ˜ì§‘"""
    print("\n" + "="*70)
    print("ì„¹ì…˜ 5: ì‹¤ì „ í”„ë¡œì íŠ¸ - ë‰´ìŠ¤ ê¸°ì‚¬ ìˆ˜ì§‘")
    print("="*70)
    
    print("\n[ì´ë¡ ]")
    print("ì‹¤ì œ ë‰´ìŠ¤ ì‚¬ì´íŠ¸ êµ¬ì¡°ë¥¼ ëª¨ë°©í•œ HTMLì—ì„œ ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•©ë‹ˆë‹¤.")
    
    # ì‹¤ì œ ë‰´ìŠ¤ ì‚¬ì´íŠ¸ì™€ ìœ ì‚¬í•œ êµ¬ì¡°
    sample_html = """
    <html>
    <body>
        <div class="news-list">
            <article class="news-item">
                <a href="/news/1" class="news-link">
                    <h2 class="news-title">íŒŒì´ì¬ìœ¼ë¡œ ì—…ë¬´ ìë™í™” ì„±ê³µ</h2>
                </a>
                <div class="news-meta">
                    <span class="press">í…Œí¬ë‰´ìŠ¤</span>
                    <span class="date">2024-01-15</span>
                    <span class="category">ê¸°ìˆ </span>
                </div>
                <p class="news-summary">
                    íŒŒì´ì¬ì„ í™œìš©í•œ ì—…ë¬´ ìë™í™” ì‚¬ë¡€ê°€ ì¦ê°€í•˜ê³  ìˆìŠµë‹ˆë‹¤.
                </p>
            </article>
            
            <article class="news-item">
                <a href="/news/2" class="news-link">
                    <h2 class="news-title">ì›¹ ìŠ¤í¬ë ˆì´í•‘ìœ¼ë¡œ ë°ì´í„° ìˆ˜ì§‘</h2>
                </a>
                <div class="news-meta">
                    <span class="press">ë°ì´í„°ì €ë„</span>
                    <span class="date">2024-01-14</span>
                    <span class="category">ë°ì´í„°</span>
                </div>
                <p class="news-summary">
                    ì›¹ ìŠ¤í¬ë ˆì´í•‘ ê¸°ìˆ ì´ ë°ì´í„° ìˆ˜ì§‘ì˜ í•µì‹¬ìœ¼ë¡œ ë– ì˜¤ë¥´ê³  ìˆìŠµë‹ˆë‹¤.
                </p>
            </article>
            
            <article class="news-item">
                <a href="/news/3" class="news-link">
                    <h2 class="news-title">BeautifulSoup ì™„ë²½ ê°€ì´ë“œ</h2>
                </a>
                <div class="news-meta">
                    <span class="press">ì½”ë”©ë§¤ê±°ì§„</span>
                    <span class="date">2024-01-13</span>
                    <span class="category">íŠœí† ë¦¬ì–¼</span>
                </div>
                <p class="news-summary">
                    BeautifulSoup ë¼ì´ë¸ŒëŸ¬ë¦¬ì˜ ëª¨ë“  ê¸°ëŠ¥ì„ ìƒì„¸íˆ ì•Œì•„ë´…ë‹ˆë‹¤.
                </p>
            </article>
        </div>
    </body>
    </html>
    """
    
    soup = BeautifulSoup(sample_html, 'html.parser')
    
    print("\n[ì˜ˆì œ 5-1] ë‹¨ê³„ë³„ ë°ì´í„° ì¶”ì¶œ")
    print("-" * 50)
    
    # Step 1: ëª¨ë“  ê¸°ì‚¬ ì°¾ê¸°
    articles = soup.select('article.news-item')
    print(f"âœ… Step 1: ì´ {len(articles)}ê°œì˜ ê¸°ì‚¬ë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤.\n")
    
    # Step 2: ê° ê¸°ì‚¬ì—ì„œ ì •ë³´ ì¶”ì¶œ
    news_list = []
    
    for i, article in enumerate(articles, 1):
        print(f"[ê¸°ì‚¬ {i}]")
        
        # ì œëª©
        title_tag = article.select_one('h2.news-title')
        title = title_tag.text.strip() if title_tag else 'ì œëª© ì—†ìŒ'
        print(f"ì œëª©: {title}")
        
        # ë§í¬
        link_tag = article.select_one('a.news-link')
        link = link_tag.get('href', '') if link_tag else ''
        print(f"ë§í¬: {link}")
        
        # ì–¸ë¡ ì‚¬
        press_tag = article.select_one('.press')
        press = press_tag.text.strip() if press_tag else 'ì–¸ë¡ ì‚¬ ì—†ìŒ'
        print(f"ì–¸ë¡ ì‚¬: {press}")
        
        # ë‚ ì§œ
        date_tag = article.select_one('.date')
        date = date_tag.text.strip() if date_tag else 'ë‚ ì§œ ì—†ìŒ'
        print(f"ë‚ ì§œ: {date}")
        
        # ì¹´í…Œê³ ë¦¬
        category_tag = article.select_one('.category')
        category = category_tag.text.strip() if category_tag else 'ì¹´í…Œê³ ë¦¬ ì—†ìŒ'
        print(f"ì¹´í…Œê³ ë¦¬: {category}")
        
        # ìš”ì•½
        summary_tag = article.select_one('.news-summary')
        summary = summary_tag.text.strip() if summary_tag else 'ìš”ì•½ ì—†ìŒ'
        print(f"ìš”ì•½: {summary[:50]}...")
        
        print()
        
        # ë”•ì…”ë„ˆë¦¬ë¡œ ì €ì¥
        news_list.append({
            'title': title,
            'link': link,
            'press': press,
            'date': date,
            'category': category,
            'summary': summary
        })
    
    print(f"âœ… ì´ {len(news_list)}ê°œì˜ ê¸°ì‚¬ ì •ë³´ë¥¼ ì¶”ì¶œí–ˆìŠµë‹ˆë‹¤!")
    
    print("\n[ì„¤ëª…]")
    print("1. article.news-itemìœ¼ë¡œ ê° ê¸°ì‚¬ í•­ëª©ì„ ì°¾ìŠµë‹ˆë‹¤")
    print("2. select_one()ìœ¼ë¡œ ê° ê¸°ì‚¬ ì•ˆì—ì„œ ì„¸ë¶€ ì •ë³´ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤")
    print("3. ë”•ì…”ë„ˆë¦¬ë¡œ êµ¬ì¡°í™”í•˜ì—¬ ì €ì¥í•©ë‹ˆë‹¤")
    print("4. ì´ íŒ¨í„´ì€ ëŒ€ë¶€ë¶„ì˜ ëª©ë¡í˜• í˜ì´ì§€ì— ì ìš© ê°€ëŠ¥í•©ë‹ˆë‹¤")
    
    return news_list


# ============================================================================
# ì„¹ì…˜ 6: CSV íŒŒì¼ë¡œ ì €ì¥í•˜ê¸°
# ============================================================================

def section6_save_csv():
    """ì„¹ì…˜ 6: ìˆ˜ì§‘í•œ ë°ì´í„°ë¥¼ CSVë¡œ ì €ì¥"""
    print("\n" + "="*70)
    print("ì„¹ì…˜ 6: CSV íŒŒì¼ë¡œ ì €ì¥í•˜ê¸°")
    print("="*70)
    
    print("\n[ì´ë¡ ]")
    print("ìˆ˜ì§‘í•œ ë°ì´í„°ë¥¼ CSV íŒŒì¼ë¡œ ì €ì¥í•˜ë©´:")
    print("- ì—‘ì…€ì—ì„œ ì—´ì–´ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤")
    print("- ë°ì´í„° ë¶„ì„ì— í™œìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤")
    print("- ë‹¤ë¥¸ í”„ë¡œê·¸ë¨ê³¼ ê³µìœ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤")
    
    # ìƒ˜í”Œ ë°ì´í„°
    sample_data = [
        {
            'title': 'íŒŒì´ì¬ ìë™í™” ì„±ê³µ',
            'press': 'í…Œí¬ë‰´ìŠ¤',
            'date': '2024-01-15',
            'link': '/news/1'
        },
        {
            'title': 'ì›¹ ìŠ¤í¬ë ˆì´í•‘ ê°€ì´ë“œ',
            'press': 'ë°ì´í„°ì €ë„',
            'date': '2024-01-14',
            'link': '/news/2'
        },
        {
            'title': 'BeautifulSoup í™œìš©',
            'press': 'ì½”ë”©ë§¤ê±°ì§„',
            'date': '2024-01-13',
            'link': '/news/3'
        }
    ]
    
    print("\n[ì˜ˆì œ 6-1] CSV íŒŒì¼ ì €ì¥ í•¨ìˆ˜")
    print("-" * 50)
    
    def save_to_csv(data, filename=None):
        """ë°ì´í„°ë¥¼ CSV íŒŒì¼ë¡œ ì €ì¥"""
        if not data:
            print("âš ï¸ ì €ì¥í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return False
        
        # íŒŒì¼ëª… ìƒì„± (íƒ€ì„ìŠ¤íƒ¬í”„ í¬í•¨)
        if not filename:
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            filename = f'news_{timestamp}.csv'
        
        try:
            # CSV íŒŒì¼ ì“°ê¸°
            with open(filename, 'w', newline='', encoding='utf-8-sig') as f:
                # í—¤ë” (ì²« ë²ˆì§¸ ë°ì´í„°ì˜ í‚¤)
                fieldnames = data[0].keys()
                writer = csv.DictWriter(f, fieldnames=fieldnames)
                
                # í—¤ë” ì“°ê¸°
                writer.writeheader()
                
                # ë°ì´í„° ì“°ê¸°
                writer.writerows(data)
            
            print(f"âœ… {len(data)}ê°œì˜ ë°ì´í„°ë¥¼ '{filename}'ì— ì €ì¥í–ˆìŠµë‹ˆë‹¤!")
            return True
            
        except Exception as e:
            print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return False
    
    # ì‹¤í–‰
    result = save_to_csv(sample_data, 'sample_news.csv')
    
    if result:
        print("\nğŸ“„ ì €ì¥ëœ íŒŒì¼:")
        print("- íŒŒì¼ëª…: sample_news.csv")
        print("- ì¸ì½”ë”©: UTF-8 (BOM) - ì—‘ì…€ì—ì„œ í•œê¸€ ê¹¨ì§ ë°©ì§€")
        print("- í˜•ì‹: CSV (ì‰¼í‘œë¡œ êµ¬ë¶„)")
    
    print("\n[ì˜ˆì œ 6-2] ì €ì¥ëœ íŒŒì¼ ë¯¸ë¦¬ë³´ê¸°")
    print("-" * 50)
    
    # íŒŒì¼ ì½ì–´ì„œ í™•ì¸
    try:
        with open('sample_news.csv', 'r', encoding='utf-8-sig') as f:
            reader = csv.DictReader(f)
            print("CSV íŒŒì¼ ë‚´ìš©:")
            for i, row in enumerate(reader, 1):
                print(f"\n{i}. {row['title']}")
                print(f"   ì–¸ë¡ ì‚¬: {row['press']}")
                print(f"   ë‚ ì§œ: {row['date']}")
    except FileNotFoundError:
        print("íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    
    print("\n[ì„¤ëª…]")
    print("1. csv.DictWriterë¡œ ë”•ì…”ë„ˆë¦¬ ë°ì´í„°ë¥¼ CSVë¡œ ì €ì¥í•©ë‹ˆë‹¤")
    print("2. encoding='utf-8-sig'ë¡œ ì—‘ì…€ì—ì„œ í•œê¸€ì´ ê¹¨ì§€ì§€ ì•Šê²Œ í•©ë‹ˆë‹¤")
    print("3. withë¬¸ìœ¼ë¡œ íŒŒì¼ì„ ìë™ìœ¼ë¡œ ë‹«ìŠµë‹ˆë‹¤")
    print("4. íƒ€ì„ìŠ¤íƒ¬í”„ë¥¼ í¬í•¨í•œ íŒŒì¼ëª…ìœ¼ë¡œ êµ¬ë¶„í•©ë‹ˆë‹¤")


# ============================================================================
# ì„¹ì…˜ 7: ì¢…í•© ì‹¤ìŠµ - ì™„ì „í•œ ìŠ¤í¬ë ˆì´í•‘ í”„ë¡œê·¸ë¨
# ============================================================================

def section7_complete_example():
    """ì„¹ì…˜ 7: ì™„ì „í•œ ì›¹ ìŠ¤í¬ë ˆì´í•‘ í”„ë¡œê·¸ë¨"""
    print("\n" + "="*70)
    print("ì„¹ì…˜ 7: ì¢…í•© ì‹¤ìŠµ - ì™„ì „í•œ ìŠ¤í¬ë ˆì´í•‘ í”„ë¡œê·¸ë¨")
    print("="*70)
    
    print("\n[ì´ë¡ ]")
    print("ì§€ê¸ˆê¹Œì§€ ë°°ìš´ ëª¨ë“  ê²ƒì„ í†µí•©í•œ ì‹¤ë¬´ ìˆ˜ì¤€ì˜ í”„ë¡œê·¸ë¨ì…ë‹ˆë‹¤.")
    
    def scrape_and_save_news(html_content=None):
        """
        ë‰´ìŠ¤ ìŠ¤í¬ë ˆì´í•‘ + CSV ì €ì¥ í†µí•© í•¨ìˆ˜
        
        Args:
            html_content: HTML ë¬¸ìì—´ (í…ŒìŠ¤íŠ¸ìš©, ì‹¤ì œë¡œëŠ” requestsë¡œ ê°€ì ¸ì˜´)
        
        Returns:
            bool: ì„±ê³µ ì—¬ë¶€
        """
        print("\nğŸš€ ë‰´ìŠ¤ ìŠ¤í¬ë ˆì´í•‘ ì‹œì‘...")
        
        # ìƒ˜í”Œ HTML (ì‹¤ì œë¡œëŠ” requests.get()ìœ¼ë¡œ ê°€ì ¸ì˜´)
        if not html_content:
            html_content = """
            <div class="news-list">
                <article class="news-item">
                    <a href="/news/1" class="news-link">
                        <h2 class="news-title">AI ê¸°ìˆ  ë°œì „</h2>
                    </a>
                    <div class="news-meta">
                        <span class="press">AIë‰´ìŠ¤</span>
                        <span class="date">2024-01-15</span>
                    </div>
                </article>
                <article class="news-item">
                    <a href="/news/2" class="news-link">
                        <h2 class="news-title">ë°ì´í„° ê³¼í•™ íŠ¸ë Œë“œ</h2>
                    </a>
                    <div class="news-meta">
                        <span class="press">ë°ì´í„°íƒ€ì„ì¦ˆ</span>
                        <span class="date">2024-01-14</span>
                    </div>
                </article>
            </div>
            """
        
        try:
            # 1. íŒŒì‹±
            print("ğŸ“– HTML íŒŒì‹± ì¤‘...")
            soup = BeautifulSoup(html_content, 'html.parser')
            
            # 2. ë°ì´í„° ì¶”ì¶œ
            print("ğŸ” ë°ì´í„° ì¶”ì¶œ ì¤‘...")
            articles = soup.select('article.news-item')
            
            if not articles:
                print("âŒ ê¸°ì‚¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                return False
            
            print(f"âœ… {len(articles)}ê°œì˜ ê¸°ì‚¬ë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤.")
            
            news_list = []
            for article in articles:
                title_tag = article.select_one('h2.news-title')
                link_tag = article.select_one('a.news-link')
                press_tag = article.select_one('.press')
                date_tag = article.select_one('.date')
                
                news_list.append({
                    'title': title_tag.text.strip() if title_tag else '',
                    'link': link_tag.get('href', '') if link_tag else '',
                    'press': press_tag.text.strip() if press_tag else '',
                    'date': date_tag.text.strip() if date_tag else ''
                })
            
            # 3. CSV ì €ì¥
            print("ğŸ’¾ CSV íŒŒì¼ë¡œ ì €ì¥ ì¤‘...")
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            filename = f'news_{timestamp}.csv'
            
            with open(filename, 'w', newline='', encoding='utf-8-sig') as f:
                fieldnames = ['title', 'press', 'date', 'link']
                writer = csv.DictWriter(f, fieldnames=fieldnames)
                writer.writeheader()
                writer.writerows(news_list)
            
            # 4. ê²°ê³¼ ì¶œë ¥
            print(f"âœ… ì™„ë£Œ! {filename}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\n")
            
            print("ğŸ“Š ìˆ˜ì§‘ëœ ë°ì´í„°:")
            print("="*70)
            for i, news in enumerate(news_list, 1):
                print(f"{i}. {news['title']}")
                print(f"   ì–¸ë¡ ì‚¬: {news['press']} | ë‚ ì§œ: {news['date']}")
                print(f"   ë§í¬: {news['link']}\n")
            
            return True
            
        except Exception as e:
            print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return False
    
    # ì‹¤í–‰
    scrape_and_save_news()
    
    print("\n[ì„¤ëª…]")
    print("ì´ í•¨ìˆ˜ëŠ” ì‹¤ë¬´ì—ì„œ ë°”ë¡œ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” ì™„ì „í•œ í˜•íƒœì…ë‹ˆë‹¤:")
    print("1. HTML íŒŒì‹± (BeautifulSoup)")
    print("2. CSS ì„ íƒìë¡œ ë°ì´í„° ì¶”ì¶œ (select)")
    print("3. ë°ì´í„° êµ¬ì¡°í™” (ë”•ì…”ë„ˆë¦¬ ë¦¬ìŠ¤íŠ¸)")
    print("4. CSV íŒŒì¼ë¡œ ì €ì¥")
    print("5. ì˜ˆì™¸ ì²˜ë¦¬ ë° ë¡œê¹…")


# ============================================================================
# ì‹¤ìŠµ ë¯¸ì…˜
# ============================================================================

def practice_missions():
    """ì‹¤ìŠµ ë¯¸ì…˜ - ì§ì ‘ í•´ë³´ê¸°"""
    print("\n" + "="*70)
    print("ğŸ’ª ì‹¤ìŠµ ë¯¸ì…˜")
    print("="*70)
    
    print("\n[ë¯¸ì…˜ 1] íŠ¹ì • ì¡°ê±´ì˜ ë§í¬ë§Œ ì¶”ì¶œí•˜ê¸°")
    print("-" * 50)
    print("ë‹¤ìŒ HTMLì—ì„œ '/news'ë¡œ ì‹œì‘í•˜ëŠ” ë§í¬ë§Œ ì¶”ì¶œí•˜ì„¸ìš”.")
    print()
    print("HTML:")
    print("""
    <div>
        <a href="/news/1">ë‰´ìŠ¤ 1</a>
        <a href="/notice/1">ê³µì§€ 1</a>
        <a href="/news/2">ë‰´ìŠ¤ 2</a>
        <a href="https://external.com">ì™¸ë¶€</a>
    </div>
    """)
    print("\níŒíŠ¸: select('a[href^=\"/news\"]')")
    
    print("\n[ë¯¸ì…˜ 2] ë³µì¡í•œ êµ¬ì¡°ì—ì„œ ë°ì´í„° ì¶”ì¶œ")
    print("-" * 50)
    print("ë‹¤ìŒ HTMLì—ì„œ ê° ì œí’ˆì˜ ì´ë¦„ê³¼ ê°€ê²©ì„ ì¶”ì¶œí•˜ì—¬")
    print("ë”•ì…”ë„ˆë¦¬ ë¦¬ìŠ¤íŠ¸ë¡œ ë§Œë“œì„¸ìš”.")
    print()
    print("HTML:")
    print("""
    <div class="products">
        <div class="product">
            <h3 class="name">ìƒí’ˆ A</h3>
            <span class="price">10,000ì›</span>
        </div>
        <div class="product">
            <h3 class="name">ìƒí’ˆ B</h3>
            <span class="price">20,000ì›</span>
        </div>
    </div>
    """)
    print("\níŒíŠ¸: select('div.product'), select_one('.name'), select_one('.price')")


# ============================================================================
# í€´ì¦ˆ
# ============================================================================

def quiz():
    """í€´ì¦ˆ - í•™ìŠµ ë‚´ìš© í™•ì¸"""
    print("\n" + "="*70)
    print("ğŸ“ í€´ì¦ˆ")
    print("="*70)
    
    questions = [
        {
            "question": "1. class='news'ì¸ ëª¨ë“  divë¥¼ ì„ íƒí•˜ëŠ” CSS ì„ íƒìëŠ”?",
            "options": ["a) div.news", "b) div#news", "c) div[news]", "d) .news.div"],
            "answer": "a"
        },
        {
            "question": "2. hrefê°€ 'http'ë¡œ ì‹œì‘í•˜ëŠ” ë§í¬ë¥¼ ì°¾ëŠ” ì„ íƒìëŠ”?",
            "options": ["a) a[href='http']", "b) a[href^='http']", "c) a[href*='http']", "d) a[href$='http']"],
            "answer": "b"
        },
        {
            "question": "3. ìì† ì„ íƒì(ê³µë°±)ì™€ ìì‹ ì„ íƒì(>)ì˜ ì°¨ì´ëŠ”?",
            "options": [
                "a) ì—†ë‹¤, ê°™ì€ ì˜ë¯¸ì´ë‹¤",
                "b) ê³µë°±ì€ ëª¨ë“  í•˜ìœ„ ìš”ì†Œ, >ëŠ” ì§ì ‘ ìì‹ë§Œ",
                "c) >ëŠ” ëª¨ë“  í•˜ìœ„ ìš”ì†Œ, ê³µë°±ì€ ì§ì ‘ ìì‹ë§Œ",
                "d) ë‘˜ ë‹¤ ì‚¬ìš©í•˜ì§€ ì•ŠëŠ”ë‹¤"
            ],
            "answer": "b"
        }
    ]
    
    for i, q in enumerate(questions, 1):
        print(f"\n{q['question']}")
        for option in q['options']:
            print(f"  {option}")
    
    print("\n(ì •ë‹µì€ í•˜ë‹¨ì˜ 'ì •ë‹µ ë° í•´ì„¤'ì—ì„œ í™•ì¸í•˜ì„¸ìš”)")
    print("="*70)


# ============================================================================
# ì •ë‹µ ë° í•´ì„¤
# ============================================================================

def show_answers():
    """ì •ë‹µ ë° í•´ì„¤"""
    print("\n" + "="*70)
    print("âœ… ì •ë‹µ ë° í•´ì„¤")
    print("="*70)
    
    print("""
<details>
<summary>ì •ë‹µ ë³´ê¸°</summary>

1. ì •ë‹µ: a) div.news
   í•´ì„¤: 'tag.class' í˜•ì‹ìœ¼ë¡œ íƒœê·¸ì™€ í´ë˜ìŠ¤ë¥¼ ì¡°í•©í•©ë‹ˆë‹¤.
         div.newsëŠ” "div íƒœê·¸ì´ë©´ì„œ news í´ë˜ìŠ¤ë¥¼ ê°€ì§„ ìš”ì†Œ"ë¥¼ ì˜ë¯¸í•©ë‹ˆë‹¤.
         div#newsëŠ” IDë¥¼ ì˜ë¯¸í•˜ê³ , div[news]ëŠ” news ì†ì„±ì„ ì˜ë¯¸í•©ë‹ˆë‹¤.

2. ì •ë‹µ: b) a[href^='http']
   í•´ì„¤: ^ëŠ” "~ë¡œ ì‹œì‘"ì„ ì˜ë¯¸í•˜ëŠ” ì†ì„± ì„ íƒìì…ë‹ˆë‹¤.
         = ëŠ” ì •í™•íˆ ì¼ì¹˜, * ëŠ” í¬í•¨, $ ëŠ” ëë‚¨ì„ ì˜ë¯¸í•©ë‹ˆë‹¤.
         ì™¸ë¶€ ë§í¬(httpë¡œ ì‹œì‘)ì™€ ë‚´ë¶€ ë§í¬(/ë¡œ ì‹œì‘)ë¥¼ êµ¬ë¶„í•  ë•Œ ìœ ìš©í•©ë‹ˆë‹¤.

3. ì •ë‹µ: b) ê³µë°±ì€ ëª¨ë“  í•˜ìœ„ ìš”ì†Œ, >ëŠ” ì§ì ‘ ìì‹ë§Œ
   í•´ì„¤: 'A B'ëŠ” Aì˜ ëª¨ë“  ìì† Bë¥¼ ì°¾ìŠµë‹ˆë‹¤ (ê¹Šì´ ë¬´ê´€).
         'A > B'ëŠ” Aì˜ ì§ì ‘ ìì‹ Bë§Œ ì°¾ìŠµë‹ˆë‹¤ (ë°”ë¡œ ì•„ë˜ 1ë‹¨ê³„ë§Œ).
         ì •ë°€í•œ ì„ íƒì´ í•„ìš”í•  ë•Œ >ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.

</details>
    """)


# ============================================================================
# ë©”ì¸ ë©”ë‰´
# ============================================================================

def show_menu():
    """ë©”ë‰´ í‘œì‹œ"""
    print("\n" + "="*70)
    print("ì›¹ ìŠ¤í¬ë ˆì´í•‘ ì…ë¬¸ - 3êµì‹œ: CSS ì„ íƒì í™œìš©")
    print("="*70)
    print("\n[í•™ìŠµ ì„¹ì…˜]")
    print("1. CSS ì„ íƒì ê¸°ì´ˆ (íƒœê·¸, í´ë˜ìŠ¤, ID)")
    print("2. ì†ì„± ì„ íƒìì™€ ì¡°í•©")
    print("3. ìì†/ìì‹ ì„ íƒì")
    print("4. ì—¬ëŸ¬ ì„ íƒì ì¡°í•©")
    print("5. ì‹¤ì „ í”„ë¡œì íŠ¸ - ë‰´ìŠ¤ ê¸°ì‚¬ ìˆ˜ì§‘")
    print("6. CSV íŒŒì¼ë¡œ ì €ì¥í•˜ê¸°")
    print("7. ì¢…í•© ì‹¤ìŠµ - ì™„ì „í•œ í”„ë¡œê·¸ë¨")
    print("\n[ì‹¤ìŠµ ë° í‰ê°€]")
    print("8. ì‹¤ìŠµ ë¯¸ì…˜")
    print("9. í€´ì¦ˆ")
    print("10. ì •ë‹µ ë° í•´ì„¤")
    print("\n[ì „ì²´ ì‹¤í–‰]")
    print("0. ëª¨ë“  ì„¹ì…˜ ìˆœì„œëŒ€ë¡œ ì‹¤í–‰")
    print("q. ì¢…ë£Œ")
    print("="*70)


def run_all_sections():
    """ëª¨ë“  ì„¹ì…˜ ìˆœì„œëŒ€ë¡œ ì‹¤í–‰"""
    sections = [
        section1_css_basics,
        section2_advanced_selectors,
        section3_descendant_child,
        section4_multiple_selectors,
        section5_news_scraping,
        section6_save_csv,
        section7_complete_example,
        practice_missions,
        quiz,
        show_answers
    ]
    
    for section in sections:
        section()
        print("\n" + "-"*70)
        input("â Enterë¥¼ ëˆŒëŸ¬ ê³„ì†...")


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    while True:
        show_menu()
        choice = input("\nì„ íƒí•˜ì„¸ìš” (0-10, q): ").strip().lower()
        
        if choice == 'q':
            print("\nğŸ‰ ì¶•í•˜í•©ë‹ˆë‹¤! ì›¹ ìŠ¤í¬ë ˆì´í•‘ 3êµì‹œë¥¼ ëª¨ë‘ ì™„ë£Œí•˜ì…¨ìŠµë‹ˆë‹¤!")
            print("ì´ì œ ì‹¤ë¬´ì—ì„œ ì›¹ ìŠ¤í¬ë ˆì´í•‘ì„ í™œìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
            print("ğŸ‘‹ í•™ìŠµì„ ì¢…ë£Œí•©ë‹ˆë‹¤. ìˆ˜ê³ í•˜ì…¨ìŠµë‹ˆë‹¤!")
            break
        elif choice == '0':
            run_all_sections()
        elif choice == '1':
            section1_css_basics()
        elif choice == '2':
            section2_advanced_selectors()
        elif choice == '3':
            section3_descendant_child()
        elif choice == '4':
            section4_multiple_selectors()
        elif choice == '5':
            section5_news_scraping()
        elif choice == '6':
            section6_save_csv()
        elif choice == '7':
            section7_complete_example()
        elif choice == '8':
            practice_missions()
        elif choice == '9':
            quiz()
        elif choice == '10':
            show_answers()
        else:
            print("âš ï¸ ì˜¬ë°”ë¥¸ ë²ˆí˜¸ë¥¼ ì…ë ¥í•˜ì„¸ìš”.")
        
        if choice != '0' and choice != 'q':
            input("\nâ Enterë¥¼ ëˆŒëŸ¬ ë©”ë‰´ë¡œ ëŒì•„ê°€ê¸°...")


if __name__ == "__main__":
    print("""
    â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
    â•‘                                                                  â•‘
    â•‘      ì›¹ ìŠ¤í¬ë ˆì´í•‘ ì…ë¬¸ - 3êµì‹œ: CSS ì„ íƒì ì •ë°€ ë°ì´í„° ìˆ˜ì§‘      â•‘
    â•‘                                                                  â•‘
    â•‘               ë‰´ìŠ¤ ê¸°ì‚¬ ìë™ ìˆ˜ì§‘ + CSV ì €ì¥                      â•‘
    â•‘                                                                  â•‘
    â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    """)
    
    print("ğŸ“š í•™ìŠµ ëª©í‘œ:")
    print("  1. CSS ì„ íƒì ë§ˆìŠ¤í„°í•˜ê¸°")
    print("  2. ë³µì¡í•œ HTML êµ¬ì¡°ì—ì„œ ì •í™•í•œ ë°ì´í„° ì¶”ì¶œ")
    print("  3. ì‹¤ì „ í”„ë¡œì íŠ¸: ë‰´ìŠ¤ ê¸°ì‚¬ ìë™ ìˆ˜ì§‘")
    print("  4. CSV íŒŒì¼ë¡œ ë°ì´í„° ì €ì¥")
    
    main()
